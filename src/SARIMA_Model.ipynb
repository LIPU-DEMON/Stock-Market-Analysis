{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6342b2c8-1175-45d8-83f9-e2277c28cc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "multiprocessing.set_start_method(\"spawn\", force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35df7ecb-7117-46db-86c2-d688d4f794ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "input_dir = \"SARIMA_data\"\n",
    "output_dir = \"SARIMA_results\"\n",
    "model_dir = os.path.join(output_dir, \"models\")\n",
    "plot_dir = os.path.join(output_dir, \"plots\")\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "os.makedirs(plot_dir, exist_ok=True)\n",
    "performance_summary = []\n",
    "def strip_model(model_fit):\n",
    "   # Remove nested attributes\n",
    "    del_attrs = [\n",
    "        \"model.data\", \"data\", \"filter_results\", \"model.endog\",\n",
    "        \"model._data\", \"model.exog\", \"model._index\", \"model.orig_endog\",\n",
    "        \"model.orig_exog\", \"model._init_keys\", \"model._init_kwds\",\n",
    "        \"model._cache\", \"model.results\", \"model.mle_retvals\"\n",
    "    ]\n",
    "    for attr in del_attrs:\n",
    "        try:\n",
    "            keys = attr.split('.')\n",
    "            obj = model_fit\n",
    "            for k in keys[:-1]:\n",
    "                obj = getattr(obj, k)\n",
    "            setattr(obj, keys[-1], None)\n",
    "        except Exception:\n",
    "            continue\n",
    " # Remove large arrays from results\n",
    "    for attr in [\"resid\", \"fittedvalues\", \"predict_results\", \"normalized_cov_params\"]:\n",
    "        if hasattr(model_fit, attr):\n",
    "            setattr(model_fit, attr, None)\n",
    "# # Remove miscellaneous metadata\n",
    "#     if hasattr(model_fit, \"_results\"):\n",
    "#         model_fit._results = None\n",
    "#     if hasattr(model_fit, \"_cache\"):\n",
    "#         model_fit._cache = {}\n",
    "\n",
    "#     return model_fit\n",
    "\n",
    "def sarima_forecast(file, forecast_days=60):\n",
    "    stock = file.replace(\"_cleaned.csv\", \"\")\n",
    "    df = pd.read_csv(os.path.join(input_dir, file))\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df.set_index('Date', inplace=True)\n",
    "\n",
    "    series = df['Close'].values\n",
    "    train = series[:-10]\n",
    "    test = series[-10:]\n",
    "\n",
    "    order = (1, 1, 1)\n",
    "    seasonal_order = (1, 1, 1, 7)\n",
    "\n",
    "    try:\n",
    "        model = SARIMAX(train, order=order, seasonal_order=seasonal_order)\n",
    "        model_fit = model.fit(disp=False)\n",
    "# Predictions\n",
    "        train_preds = model_fit.predict(start=0, end=len(train)-1)\n",
    "        test_preds = model_fit.predict(start=len(train), end=len(train)+len(test)-1)\n",
    "        future_preds = model_fit.predict(start=len(train)+len(test), end=len(train)+len(test)+forecast_days-1)\n",
    "# Metrics\n",
    "        train_rmse = np.sqrt(mean_squared_error(train, train_preds))\n",
    "        test_rmse = np.sqrt(mean_squared_error(test, test_preds))\n",
    "        train_mae = mean_absolute_error(train, train_preds)\n",
    "        test_mae = mean_absolute_error(test, test_preds)\n",
    "# Strip model to reduce size\n",
    "        # model_fit = strip_model(model_fit)\n",
    "# Save model\n",
    "        model_path = os.path.join(model_dir, f\"{stock}_sarima_model.pkl\")\n",
    "        joblib.dump(model_fit, model_path, compress=3)\n",
    "        size_mb = os.path.getsize(model_path) / (1024 * 1024)\n",
    "# Plot test predictions\n",
    "        test_index = df.index[-10:]\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(test_index, test, label='Actual')\n",
    "        plt.plot(test_index, test_preds, label='Predicted')\n",
    "        plt.title(f\"{stock} - SARIMA Test Forecast\")\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(\"Price\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(plot_dir, f\"{stock}_test_plot.png\"))\n",
    "        plt.close()\n",
    "        performance_summary.append({\n",
    "            \"Stock\": stock,\n",
    "            \"Train_RMSE\": round(train_rmse, 4),\n",
    "            \"Test_RMSE\": round(test_rmse, 4),\n",
    "            \"Train_MAE\": round(train_mae, 4),\n",
    "            \"Test_MAE\": round(test_mae, 4),\n",
    "            \"Model_Size_MB\": round(size_mb, 2)\n",
    "        })\n",
    "    print(f\"{stock},Train RMSE={train_rmse:.2f}, Test RMSE={test_rmse:.2f} , Model Size={size_mb:.2f} MB\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed for {stock}: {e}\")\n",
    "# Run for all files\n",
    "for file in os.listdir(input_dir):\n",
    "    if file.endswith(\"_cleaned.csv\"):\n",
    "        sarima_forecast(file)\n",
    "# Save performance summary\n",
    "summary_path = os.path.join(output_dir, \"sarima_performance_summary.csv\")\n",
    "pd.DataFrame(performance_summary).to_csv(summary_path, index=False)\n",
    "print(f\"Performance summary saved to {summary_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (FixEnv)",
   "language": "python",
   "name": "jupyterfix"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
